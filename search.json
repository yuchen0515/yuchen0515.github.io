[{"title":"MIRlab - owen.lin RD page","url":"/202209_MIRlab-owen-lin-RD-page/","content":"\nRef. http://mirlab.org/jang/mir/howToBuildPersonalRdPage.asp\n說明：身為 MIRlab 多媒體資訊檢索實驗室的一員，會建立 RD page 置放個人研發相關資訊，如：讀過的論文、專案和連絡方式等。為避免放上實驗室主機後頁面難以維護，故透過 mirlab 網址導向至此，以利於維護之。\n\n\n林育辰 Yu-Chen LinEducation\nM. S., Department of Computer Science and Information Engineering, National Taiwan University, Sep. 2022~present\nB. S., Department of Computer Science and Information Engineering, National Taiwan Normal University, Sep. 2018~Jun. 2022\n\n實驗室內職責\nNAS 機器管理\n技術賦能組\n語音組 —&gt; NLP 組\n\n\nResearch我目前在 Ansys 實習，主要研究大型語言模型的應用，如：LLM 於「專業領域」的 Q&amp;A 問答，亦或是 工程領域上的程式碼補全等等，會預期會以 “Code Generator” 的方向為碩論主題。當前固定週三早上 Machine Learning Team Meeting 以及 每週五早上的 Weekly Meeting (我一人報告，與其他三四位專家討論)。若有新進展則會在 MIRlab 的 NLP Group 討論/分享。\n以下我所閱讀的論文大多數以 自然語言處理 為主軸，未必涵蓋所有看過的論文，以下是我較有印象的。\nRead papers\nNye, Maxwell, et al. “Show your work: Scratchpads for intermediate computation with language models.” arXiv preprint arXiv:2112.00114 (2021).\nMohamed, Abdelrahman, et al. “Self-supervised speech representation learning: A review.” IEEE Journal of Selected Topics in Signal Processing (2022). (Reading)\nYao, Shunyu, et al. “React: Synergizing reasoning and acting in language models.” arXiv preprint arXiv:2210.03629 (2022).\nDua, Dheeru, et al. “Successive prompting for decomposing complex questions.” arXiv preprint arXiv:2212.04092 (2022).\nSchick, Timo, et al. “Toolformer: Language models can teach themselves to use tools.” arXiv preprint arXiv:2302.04761 (2023).\nSchäfer, Max, et al. “Adaptive test generation using a large language model.” arXiv preprint arXiv:2302.06527 (2023).\nZhao, Wayne Xin, et al. “A survey of large language models.” arXiv preprint arXiv:2303.18223 (2023). (Reading)\nPeng, Baolin, et al. “Instruction tuning with gpt-4.” arXiv preprint arXiv:2304.03277 (2023). (Reading)\nPark, Joon Sung, et al. “Generative agents: Interactive simulacra of human behavior.” arXiv preprint arXiv:2304.03442 (2023).\nChiang, Cheng-Han, and Hung-yi Lee. “Can Large Language Models Be an Alternative to Human Evaluations?.” arXiv preprint arXiv:2305.01937 (2023).\nChen, Lingjiao, Matei Zaharia, and James Zou. “FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance.” arXiv preprint arXiv:2305.05176 (2023).\nWang, Yue, et al. “Codet5+: Open code large language models for code understanding and generation.” arXiv preprint arXiv:2305.07922 (2023). (Reading)\nWang, Peiyi, et al. “Large language models are not fair evaluators.” arXiv preprint arXiv:2305.17926 (2023).\nThakur, Shailja, et al. “VeriGen: A Large Language Model for Verilog Code Generation.” arXiv preprint arXiv:2308.00708 (2023).\nZheng, Lianmin, et al. “Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.” arXiv preprint arXiv:2306.05685 (2023).\nHe, Zhuolun, et al. “ChatEDA: A Large Language Model Powered Autonomous Agent for EDA.” arXiv preprint arXiv:2308.10204 (2023).\nSun, Mingjie, et al. “A Simple and Effective Pruning Approach for Large Language Models.” arXiv preprint arXiv:2306.11695 (2023). (Reading)\n\nRead articles\n這裡指的是普通的技術文章，而不一定是指學術專精的 article\n\n\n淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中\nSelf-supervised learning and its applications to speech processing(李宏毅教授短講)\n\nRead video-  機器學習 2023 - 生成式AI 系列影片Read video - 宏毅老師系列\n【機器學習2021】生成式對抗網路 (Generative Adversarial Network, GAN) (一) – 基本概念介紹\n【機器學習2021】生成式對抗網路 (Generative Adversarial Network, GAN) (二) – 理論介紹與WGAN\n【機器學習2021】自督導式學習 (Self-supervised Learning) (一) – 芝麻街與進擊的巨人\n【機器學習2021】自督導式學習 (Self-supervised Learning) (二) – BERT簡介\n【機器學習2021】自編碼器 (Auto-encoder) (下) – 領結變聲器與更多應用\n【機器學習2021】來自人類的惡意攻擊 (Adversarial Attack) (下) – 類神經網路能否躲過人類深不見底的惡意？\n【機器學習2021】機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？\n【機器學習2021】機器學習模型的可解釋性 (Explainable ML) (下) –機器心中的貓長什麼樣子？\n【機器學習2021】概述領域自適應 (Domain Adaptation)\n【機器學習2021】概述增強式學習 (Reinforcement Learning, RL) (一) – 增強式學習跟機器學習一樣都是三個步驟\nTransformer\nELMO. BERT, GPT (Reading)\n\n\nCompetition\n最佳成績：第一名, 臺大「深度學習之應用」期末 Hahow 課程預測競賽\n優勝 (第六名), 玉山人工智慧公開挑戰賽 2022 夏季賽 —— 語音辨識後修正, 林育辰, 梁俊彥\n競賽筆記：https://hackmd.io/@mathlin/BJ4J1Nuc5\n心得文章：https://reurl.cc/1mKoOY\nGithub：https://github.com/yuchen0515/2022-Competition-CUDAOutOfMemory\n\n\n\n\nProject\n字幕生成系統 (A Subtitles Generator using WeNet Toolkits)\n輸入 YouTube 網址可抽取音訊，生成其對應字幕之展示系統\n於 DSP 課程中獲 A+ 成績，其持續衍生開發，目前為 MIRlab 展示成品之一\n\n\n\n\nMeeting Slide\n[Password]  [Slide Folder]\nNote: Password 限內部有帳號者才能存取，得到 Password 後，可進入 slide folder 鍵入 password 即可觀看全年的報告投影片。\n\n\n其他\n手冊：[技術賦能組], [語音組手冊] (手冊大部分由我建置與撰寫，若需連結請私訊或翻 LINE 群組記事本)\n\n\nCourse碩士\n機器學習 (Machine Learning, ML), 李宏毅老師\n深度學習之應用 (Applied Deep Learning, ADL), 陳縕儂老師\n數位語音處理概論 (Introduction to Digital Speech Processing, DSP), 李琳山老師\n自然語言處理 (Natural Language Processing, NLP), 陳信希老師\n高等電腦視覺 (Advanced Computer Vision, ACV), 傅楸善老師\n智慧型汽車導論 (Introduction to Intelligent Vehicles), 林忠緯老師\n類神經網路 (Neural Network, NN), 劉長遠老師\n腦理論 (Brain Theory), 劉長遠老師\n\n大學\n資料探勘、資料視覺化、計算機圖學、影像處理\n人工智慧、啟發式演算法與解題應用\n區域性網路、資料通訊\n資料庫理論\n生物技術、生物資訊應用程式語言、生物資訊學導論\n作業系統、計算機結構、電腦輔助VLSI設計、組合語言、數位邏輯\n程式設計（一）（二）、進階程式設計\n演算法、資料結構\n機率論、線性代數、離散數學、微積分乙（一）（二）\n…, 共計：150.0 學分\n\n\nContact\n /i98565412@gmail.com\n /yuchen0515\n /Yu-Chen Lin\n\n","categories":["實驗室"],"tags":["MIRlab"]},{"title":"賽後心得-「看見你的聲音--語音辨識後修正」","url":"/202207_%E8%B3%BD%E5%BE%8C%E5%BF%83%E5%BE%97-%E3%80%8C%E7%9C%8B%E8%A6%8B%E4%BD%A0%E7%9A%84%E8%81%B2%E9%9F%B3-%E8%AA%9E%E9%9F%B3%E8%BE%A8%E8%AD%98%E5%BE%8C%E4%BF%AE%E6%AD%A3%E3%80%8D/","content":"前言\n決定命運的，不是偶然而是選擇。—電視劇 金裝律師 (Suits)\n\n過往的失意，鬱結為一股不具名的悲傷，慢慢地，蛻變為養分。大學後我開始注重自己的選擇，追尋自己的意志，探索自己要的是什麼，結果是—迎來戲劇性的大學生涯。\n雲霄飛車，一次次跌宕起伏，大學生涯亦然。突然發現自己喜愛資訊領域，進入後突然被抓去比賽，小有成就卻慘敗，進入一股低潮。莫名的，就站在舞台上，獲頒那夢寐以求的銅獎…替我曾經覺得遙不可及的奧匹資訊賽命題。\n糊裡糊塗的倉促準備實習，進到我想進的公司 KKBOX。卻意外勾勒起落地又揚起的音符—「語音」與興致勃勃的我。於是隨性地訂下持續升學並研究語音辨識的目標。我想…很慶幸的，我並不是源自於對出社會的恐懼而升學，也並非背負家人的選擇而選擇，而是衷於我自己的想望，這是我最幸運的一件事。\n去年十一月，推甄上台大資工所，並如願加入「多媒體資訊檢索實驗室」的語音組，此時的我像剛進入幼兒園，純真而好奇地探索每樣事物，懵懵懂懂地甚是純真，緩步地吸取新知。\n我想，並沒有所謂的偶然，而是選擇決定了自己的命運吧！\n緣起實習、實驗室和課程，如此稀疏平常的生活一天天過去了。某天，兩位涉世未深的「碩 0 生」被指派參加玉山銀行舉辦的「看見你的聲音—語音辨識後修正」競賽，沒錯…其中一位就是我！\n\n介紹我們參加的是玉山銀行主辦的「看見你的聲音—語音辨識後修正」，看起來倒像綠豆糕，痾…不是！看起來很像「語音辨識」的主題，不過這塊領域長期是乏人問津，投入該領域的人並不多。事實上，他是「後修正」，意即做完語音辨識後，以「自然語言處理 (Natural Language Processing, NLP)」手法再進一步修正。\nNLP 領域其實也並不多人，因此該比賽在 T-brain 平台上是最少人參與的，即便如此，仍有一百一十九隊參加！\n銀行業近年來盛行導入智慧 AI 機器人，而該場比賽情境也十分雷同。玉山 APP 提供智慧化的語音服務，服務接受使用者的聲音後，經過 ASR (Automatic Speech Recognition) 模型辨識，產生出前十可能對應的語句—這些都是前半段「語音辨識」所屬的範疇。\n賽事所做的就是後半段的「語音後修正」，依據語音辨識的結果，可利用不同候選句之間的關聯再次糾正，即為本次賽事的主要任務，不過…當然不僅如此而已，比賽較像是要求我們提供「正式對外服務」，我們需要架設 API Server 對外提供服務…！\n每筆 Request 即為可能語句列表、時間和重試次數等等，當服務接受需求後，必須在一秒內回傳一句結果。然而…要命的來了，同時可能有十筆 Requests 席捲而來！更何況是在日益肥大的 NLP 領域達成這樣的豐功偉業，也因此一度「人性化」地在賽中放寬至兩秒，但仍舊是個很浮誇的需求。\n小小不幸何謂不幸？身為涉世未深的碩 0 學生，在賽事開始後一個月才參賽，以一個狀況外的鄉巴佬姿態誕生，如同新手逛街打怪，遇見地獄大魔王一般。我與隊友更是第一次參加 AI 相關賽事，憑藉隊友曾是 NLP 的過客，配合我在實習鍛鍊的後端能力，組成一支全面性俱佳的隊伍—CUDAOutOfMemory。\n敝隊駕馭的電腦配備兩張 GeForce GTX 1080 Ti，而在我們初次與其相見歡的剎那，Out Of Memory 纏身—就那樣…戲謔性地成為了隊名XD\n\nNLP Model綜觀比賽本身，可以注意到不僅後端需求相當高，以語句本身的 baseline 亦是相當傑出，約略為 9.34 % CER (Character Error Rate)，這是經過玉山 ASR 辨識後的最佳結果。奠定在這基礎上，還想要更好的表現實屬不易，還得承受高強度的需求，只能說獲獎希望渺茫，藍瘦香菇啊……\n我們選擇肥碩的 Transformers model，將「糾錯問題視為一種翻譯任務」展開一系列操作，添加額外文本  CLMAD、產生錯誤文本、困惑度 (Perplexity, PPL) 和 nlp-fluency。不幸地，在測試賽效果都十分有限。\n零零總總的各方嘗試，於最終正式賽改進了 1 % 的 CER，成為唯一的 100% 使用 Supervised Learning 仍能獲獎的隊伍，真是萬幸啊XD\n\nAPI Server而我在這場比賽中，一肩扛起後端的重責。將這樣一個重大任務，交給一位初出茅廬，或許談不上是「後端工程師」的我來主掌，這隊也沒人才了…命在旦夕，得獎希望黯淡無光且渺茫啊…！\n悵然若失、眼神空洞的….實驗室主機，一聲長嘆，然後一操再操。身為前六名中少數「超在意」後端的隊伍，也是少數從後端層面一次次加速，而達到賽事的要求，這也算是對實習一年來的成果驗收吧！\n而接下來，就要面對一波波狀況，見招拆招了 :P\n狀況一想像一下，你在玩 Random Dice 這款骰子塔防遊戲。\n\n身為左邊的玩家，你可愛的骰子們等級都太嫩，一隻敵人就應付不暇，更何況後面一條龍。是的，由於 NLP Model — Transformers 的肥大，依據推論高達 2300 ms，遠超過主辦方要求，一個應付不暇，更何況一次來十個？\n那麼，就得先針對問題本身思考，盡可能去蕪存菁。候選句全部都很重要嗎？這是第一個問題。人眼掃描後，可以發現越後面的語句越荒謬，在應付不暇的狀況下，其實第一句就已經堪用，保留了許多最重要的資訊了。\n接下來，就得思考「模型」真有需要那麼「深度」嗎？由於訓練資料寡寡可數，大概六萬筆稱不上是大資料，Model level 太深，或許還有過度擬合 (Overfitting) 的風險，故可將層級壓低些。\n如此一來，服務進展到單筆 700 ms 的狀態，可說是一大里程碑。但你可要知道「一個打十個」是多麽剽悍的事實。\n狀況二面對十個敵人，全數解決僅花一秒鐘。顯然地，隨著敵人增加，打倒全部所需的時間勢必也會線性成長，這對於服務本身也是相同的狀況。\n因此，可從幾個層面著手：\n\n排程—Queue vs. Concurrent\n設備—CPU vs. GPU\n拒絕滿分—「想守住越多，失去的越多」\n\n拒絕滿分這項，其實離我們都很近。上了高中，若抱持著題題斃命的心態，數學就會使你一槍斃命。因此在以某種策略挑選題目一個個解出，才能達到最佳表現。而在本次賽事中，已知語句列表是按照排行榜排序的，因此若無暇處理它，那就回傳最佳的語句，就是一種損失最少的方式。\n當前處理程序的方式屬於 佇列 (Queue) 排隊式的，程序其實和交通很相似，雪隧一但遭遇事故，整條國五就會呈現紫色地獄。如果有多條道路疏通，那就太好了！在處理要求 (Request) 就會面臨類似的窘境，但若以 Concurrent 的方式，則會讓整體服務速率都降低，若整體速率高於一秒，就更淒慘了…一筆也完成不了。\n以 Concurrent 方式處理要求，我們實驗了 WSGI, Nginx 等正式部署工具，最終以 Flask 內建的 Thread 效能最佳，與其他兩項工具效能相差近三成。\nFlask Thread 事實上是利用「快速切換」，在多筆 Request 間流轉、輪替，達成近似於「同時」處理的效果，而非真正意義上的「同時」，這是 Python 本身語言上的限制所致。總而言之，暫時以這樣的方式，配合 奴役 GPU 1080 和這三大策略，順利獲得以下的回應效能。\n拒絕滿分這項，其實離我們都很近。上了高中，若抱持著題題斃命的心態，數學就會使你一槍斃命。因此在以某種策略挑選題目一個個解出，才能達到最佳表現。而在本次賽事中，已知語句列表是按照排行榜排序的，因此若無暇處理它，那就回傳最佳的語句，就是一種損失最少的方式。\nFigure. 第一次昇華的 Response Time\nResponse Time Graph 會記載「何時」收到的 Request，每筆 Request 間隔多久才回傳結果，可以很直觀地看到整體服務的狀況是否在時間內。很顯然地在上圖中隱隱約約不妙、悲劇溢於言表，多筆 Request 回應時間高於兩秒，這代表整體效能還是不夠快。\n狀況三—Batch同時處理大量需求，始終會因為「高速」輪替而犧牲掉變換的時間 (context switch)，換個角度思考，是不是可以設定一個時間，在這段時間內盡可能搜集 request，時間到時一口氣同時處理，那麼配合 GPU 平行處理的威力，肯定能提高效能的吧！？\n結果找到了這項工具 ShannonAI/service-streamer 完成了這項豐功偉業，Throughput 5.7 / sec 提升至 14.5 / sec，效率為原本的 254 % 之多。啊…斯巴拉西 (素晴らしい)！！Figure. 脫胎換骨的 RTG 結果\n測試速度到位了，就得進到測試，這是個博大精深的學問…\n而我們用了三種方式一一去確認我們服務的運作、速率，以及在高壓狀態下是否能照常服務：\n\npostman 使我們能檢測 API 服務是否正常運作\ngrequest 這項 Python 套件則讓人可對同時傳送 request 客製化\nJMeter 模擬十名使用者輪替傳送 request\n\n一項產品上線後能否正常維運，壓力測試是很重要的環節，而你要盡可能的「高壓」去欺凌你自己的服務，把自己當成「壞壞使用者」去設計一些奧客才會做的事在測試裡頭，長句、錯誤句等等，若服務能夠安然無恙的照常運作與輸出，那服務「可能」就沒問題了。\nFigure. Stress testing\n上圖為 JMeter 的測試曲線圖，這套工具是提供測試的開源軟體，能夠模擬多名使用者運用服務的承載狀況。而從圖中能注意到紅、綠和藍色等等不同的曲線：\n\n流通量 (Throughput)：每分鐘能處理的需求 (Request) 量。\n平均時間 (Average)：每筆需求處理的平均時間 (毫秒)。\n中位時間 (Median)：所有樣本 (sample) 按照處理時間排序後之中位數。\n\n另外，可以設定「暖機」時間，在一個現實運作的服務中，流量也是逐步的上升與下降。我們可以仿照這樣的情境，設定幾秒後才達到最大用戶數，也因此綠色的流通量曲線並不是起初就維持高輸出，而是配合暖機時間逐步上升的。當然，JMeter 作為一個專業的測試工具，還有許多擬真情境的功能可以嘗試！這邊就不一一說明了。\n總之！從這張圖中透露出服務能夠穩定的輸出某個定值，而單就當前的需求量而言，並不會影響到整體服務的效能，故能夠判定「可承受」比賽規格的服務需求。\n架構圖總之！從這張圖中透露出服務能夠穩定的輸出某個定值，而單就當前的需求量而言，並不會影響到整體服務的效能，故能夠判定「可承受」比賽規格的服務需求。\nFigure: API Server 架構圖\n關於本隊的 API Server 是時候該做個總結了，以上是本隊的系統架構圖，流程大致如下：\n\n玉山發出 POST Request\nFlask Server 為每個 Request 各創建一個 Thread 處理之\n蒐集 150 毫秒以內的 Request，最大容量為 64 筆\n每 150 毫秒 或超出容量上限，即 批次處理 (Batch)\n對於每筆 Request，檢查與判定，若符合規格就跑 Model，否則直接吐回 TOP1 的語句內容。這邊回傳給 Request 對應的 Thread\n回傳結果給玉山的伺服器\n\n賽後檢討流程大致上並無問題，也蠻順暢的。事後重新省視賽況和程式碼，認為以下幾點仍可改良：\n\nnvidia-docker： 運作時，有一段流程會不斷地查詢網路上的特定資源，以致於效率拖沓。因此，可以追蹤整體執行流程，將那些資源送進本機端維護並且定期更新，以本機端形式查閱，能提高約略三成的效能。\nmulti-GPUs：由微軟公開的 ZeRO &amp; DeepSpeed 加速技術，能夠將 NLP 模型龐大的參數攤分在若干個 GPU 上，能夠有效提升效能。\nRedis：是一種 Key-Value 的資料儲存形式，能夠高速查詢資料。因此我們能將超時的 Request 計算結果與唯一的任務代碼對應，那麼若再次重新發送就能夠接力計算，節省已逝去的時間。而本次使用的 service-streamer 工具中有提供 Redis 以 batch 方式加速的功能。\nProcesses：常言「雞蛋不能放在同個籃子裡」，若以單個 Process 組織整套系統，當該筆 Process 出了狀況，將葬送整個服務。而以本次系統架構而論，即為單筆 Process 再分割出若干個 Thread 執行不同任務，因此日後得多在 multi-process 和 排程這塊琢磨，並需更加留意「例外」的處理形式。\n程式碼維護：本次設定檔以及參數等工具不夠全面，只做了一半，如 Config 檔在 api 程式碼中就沒有使用，ArgumentParser 參數工具反倒是常更改的參數沒有寫進去。另一方面，由於程式碼撰寫頗為急促，故無暇顧及 “clean code”，這些都是未來可以改進的方向。\n\n\n插曲——大災難競賽有若干個階段，亦有兩梯次的測試賽以及正式賽。測試賽為期三天，在指定期間內每日晚間六點，準時轟炸你各位參賽者，一共四千題，完全比照正式賽之規格。而正式賽與測試賽唯一不同的在於連續日期從三天變為四天。\n自詡為奴隸 (也許他並沒這樣說XD) 的實驗室電腦，很僥倖地在兩次測試賽長達六天內並未出任何狀況，盡心盡力地為我們付出，並穩定地繳交出兩萬四千題的答案。\n然而同學間戲弄改編的名言：「關鍵時刻比衰小！」總是剎那間恍惚一瞬發生…正式賽第三天—我最忙碌的一天…發生了事故。當天早上，實驗室電腦們接一連二地發生狀況，或許是被攻擊，我們家的是自行關機，但這一重開機 CUDA 就出問題了，使得 GPU 1080 Ti 絲毫無用武之地…\n左右觀察法—每個人都知曉的祕技，據聞是在考試時左看看、右看看就能獲取答案。而我使出了忍術「上下觀察法」，非常單純，如白雪般皎潔無瑕。僅僅是觀察位於自己前後兩支隊伍，前面 (第五名) 差距不小，而後面 (第七名) 也有著不容忽視的鴻溝，權衡之下，假設第三、第四天已 “baseline” 成績作結，綜合前兩天平均可以穩妥地取得第六名，那麼維持 “baseline” 採取最安全穩定的做法就萬事休矣了！\n不久，迅速完成一個「無腦」服務，能夠在連線瞬間將 Request 內容列表第一句話吐回去，啊！真是完美！最終憑藉這樣穩定的服務度過比賽的下半餘生，並達成了領獎資格要求「低於 baseliine」之成績，以第六名作收，可喜可賀。\n其實從這次事件中，可以學到兩件事：\n\n一、不要太有自信\n\n切忌，勿對服務的穩定性太有信心，必須戒慎恐懼好好關切他！本地端終究是有風險，除了遇到意外而終止程序外，當然還有「不可抗力」類型的機器罷工！上雲與地端都有各自的好處，但若能發展「監控」服務主動通知，並且有緊急應對的方式，才能應對服務的各種狀況。\n\n二、「爛」方法其實很好\n\n“Baseline” 什麼都不做—站在比賽以及服務的立場上，是相當切實的手法。比賽力求成效，而在已知能夠穩定獲取名次的狀況下，穩，再求精進才是上策，而勿追求卓越而功虧一簣，十分可惜。\n服務依然以穩定為優先，而若全掛相當於 P0 事件，盡可能讓損失降低才是上策，因此若能夠緊急恢復出一個堪用版本，就幾乎只寫了一大半。能夠在緊急且資源有限的狀況下，盡可能地權衡局勢，致力於降低損失，會是提供服務時最重要的事情。\n如何做得更好這是我在賽後不斷思索的一件事，而從不同隊伍的做法中，領悟到幾件事情…\n\n一、看清資料的本質\n\n從官方給的六萬筆訓練資料中，若仔細觀察可以注意到有不少類似於新聞標題的語句：「行政院擬發放五倍券」，但也有很生活化的語句：「我想進行匯兌服務」。因此資料本身可以分成兩種取向：一般、新聞，並且很顯然的糾正這兩種不同類型的語句，應無法以相同的邏輯去糾正他。\n除了語料源頭的分類以外，從測試資料本身亦可以做出不少變化。如同：「近年來股市迭宕不停」這樣的語句，從相似詞上看，「股市」或許容易被辨認為「不是」，每個語句會有多種相似詞彙，經過語音辨識後所辨識之語句，最有可能是「音對字不對」的狀況。\n因此，我們可以建立「相似字詞典」，將單筆測資利用相似字詞典排列組合，塑造出更多測試資料。合理地推估六萬筆資料可擴增五倍、六倍以上，用以訓練模型的話，更可再進一步下降 1% 上下的 CER。\n\n二、快，還要更快！\n\n有很多加速技巧是沒碰過、聽過就不會知曉的，例如：微軟公開的 ONNX Runtime 是以 ONNX 格式儲存，能以其技術加速五倍以上的推理速度。亦或是攤分參數的技術，一樣是微軟開發的 ZeRO 以及 DeepSpeed，能將現有資源最大的活化。若能夠再配合本隊本次使用的 Batch 技術，那麼甚至可以一秒內同時應付二十筆 Requests 是很可能的。\n結語本次賽事我們兩位涉世未深的 碩 0 好夥伴費盡了心力，用了許多技術，難能可貴的能在第一次參與這樣的比賽，就搶到很前面的名次，獲得獎項，這也很超乎我們的預期。\n不僅如此，更驗證了過去一年實習絕非虛度，技術上有深度進展，軟實力亦是。奠定在此基礎上，熟悉了整個系統維運與加速的程序，也學習到更多技巧可以運用，相信下次會更得心應手！\n這次比較可惜的就是整體上過於倉促，沒有看透資料本身，能達到的成效就會有所囿限，加速上也有很多手法可以併用，希望下次能有類似的比賽能夠參與，也期許未來能提供更穩定且快速的系統，在四處都留下我們的蹤跡吧！\n\n&lt;以下是本次賽事的程式碼以及影片&gt;\n\nRepo: https://github.com/yuchen0515/2022-Competition-CUDAOutOfMemory\nYoutube: https://youtu.be/l-A8QkgyIxo\n原文：https://medium.com/@mathlin/賽後心得-看見你的聲音-語音辨識後修正-f6d147ff9950\n\n","categories":["技術文章"],"tags":["競賽","Transformers","NLP","Flask","CUDA","Service-Streamer"]},{"title":"那些路過的 me 因們","url":"/202305_%E9%82%A3%E4%BA%9B%E8%B7%AF%E9%81%8E%E7%9A%84-me-%E5%9B%A0%E5%80%91/","content":"註記以下迷因不代表本台立場XD若你有好的迷因歡迎提供！可能不全都是迷因，只是好笑的東西 (?)\n\n\n    \n\n\nSource: Twitter@javascriptual\n\n\n\n    \n\n\nSource: Twitter@TheProgrammerMe &amp; 好色龍\n\n\n\n    \n\n\nSource: 資料科學家的工作日常\n\n\n\n    \n\n\nSource: IG@two.steps1011\n\n\n\n    \n\n\nSource: https://www.dcard.tw/f/meme/p/238725035\n\n\n\n    \n\n\nSource: FB - 路觀 / 台大博雅\n\n\n\n    \n\n\nSource: 我推的孩子 / FB - 動漫本部 2.0\n\n\n\n    \n\n\nSource: Twitter@deepfates &amp; 好色龍\n\n\n\n    \n\n\nSource: FB - 不會冷 (貼文)\n\n","categories":["雜筆"],"tags":["meme"]},{"title":"～關於我的文章規劃～","url":"/202305_%EF%BD%9E%E9%97%9C%E6%96%BC%E6%88%91%E7%9A%84%E6%96%87%E7%AB%A0%E8%A6%8F%E5%8A%83%EF%BD%9E/","content":"關於此廢文 (X)各位好，我平時喜歡和人分享、討論技術，但由於對文章要求太高，又常常太忙…希望撰寫成像 LeeMing 那樣詳盡的文章，而拖延症一而再再而三的誕生，真是沒救了…\n \n 關於後續文章規劃有若干個可能性：\n\nneovim 的絲滑之旅\n近兩個月來從 vim 轉到 neovim，彷彿有從 Windows 轉到 Linux 的豁然開朗 (X)。可能包含怎麼從 0 開始到使用 neovim 很絲滑，亦或是常見的快捷鍵整理，也可以包括我最近研究的 LaTeX + neovim 的絲滑組合，彷彿在 local 端有了 overleaf 般的舒暢，都是可以談論的範圍。\n\n\n\n\nKKBOX 實習分享\n\n這個欠超久了…之前都只有簡單寫 FB、Linkedin，我從中真的獲得很多也非常開心，但反而使我覺得不管怎樣寫都不夠好，結果就一直拖延「正式」實習心得文了QQ\n\n\n字幕生成系統是怎麼煉成的\n\n關於這個是從我跟同學在台大 DSP 課程期末專題誕生的產物，起初希望可以偷懶，把上課影片都扔進去跑一次，直接讀字幕快速上課。但之後發現使用的 WeNet Toolkit 無法應付中英混雜，加上教授授課都習慣中英混雜。近期串接 Whisper 模型，正確率高得嚇人，包括老師說「老師把毛衣脫起來一下」都正確辨識無誤，中文、英文都辨識的很好，最後也拿來輔助我們期中考準備。之後想做一個 side project，規劃字幕生成系統的前後端，同時因為 Whisper 是需要一定程度的算力的，希望可以規劃一個系統可以控制流量XD 而我相信也會是一個很好用的工具\n\n\n…\n\n當然，對什麼有興趣，或支持其中哪一項文章之誕生也可以留言XD\n","categories":["雜筆"],"tags":["計畫"]}]